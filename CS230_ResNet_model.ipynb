{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZ13_a3m-PoI"
      },
      "outputs": [],
      "source": [
        "# Import modules\n",
        "import cv2\n",
        "import pickle\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import csv\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive\n",
        "\n",
        "# Import Keras modules and its important APIs\n",
        "import keras\n",
        "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
        "from keras.layers import AveragePooling2D, Input, Flatten\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "from keras.datasets import cifar10"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mount google drive\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "metadata": {
        "id": "3CLUCXGk5u7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LOAD NON AUGMENTED DATA"
      ],
      "metadata": {
        "id": "49EK_duWuhso"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read img_name and label from csv file then upload image with img_name\n",
        "line_count = 0\n",
        "total_images = 0\n",
        "path = '/content/path_to_images'\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "with open('/content/filenames_and_labels.csv', newline='') as csvfile:\n",
        "  csvfile = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
        "  for row in csvfile:\n",
        "    if line_count == 0:\n",
        "      line_count += 1\n",
        "    else:\n",
        "      img_name = row[1]\n",
        "      if os.path.isfile(os.path.join(path, img_name)):\n",
        "        img = cv2.imread(os.path.join(path, img_name))\n",
        "        X.append(img)\n",
        "        y.append(row[2])\n",
        "        total_images += 1\n",
        "      else:\n",
        "        pass\n",
        "      line_count += 1\n",
        "    if line_count % 100 == 0:\n",
        "      print(line_count)\n",
        "  print(f'Processed {line_count} lines from CSV file.')\n",
        "  print(f'Imported {total_images} images into input X.')"
      ],
      "metadata": {
        "id": "jGx_x2twOFX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> Implement data augmentation techniques of your choosing based on the nature of the images and the number of extra images required."
      ],
      "metadata": {
        "id": "7LeTpsr7OHqM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPORT AUGMENTED DATA"
      ],
      "metadata": {
        "id": "aF0ST9vVue0D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = pickle.load( open( \"/content/augmented_X.p\", \"rb\" ) )\n",
        "y = pickle.load( open( \"/content/augmented_y.p\", \"rb\" ) )"
      ],
      "metadata": {
        "id": "aPJnyPpqQfLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train - test split\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=25)\n",
        "\n",
        "# Convert lists to np arrays\n",
        "x_train = np.array(x_train)\n",
        "x_test = np.array(x_test)\n",
        "\n",
        "# Convert y_train and y_test data from string to int ('0.0' to 0)\n",
        "y_train = np.array(y_train, dtype=\"float\")\n",
        "y_train = np.array(y_train, dtype=\"int\")\n",
        "y_test = np.array(y_test, dtype=\"float\")\n",
        "y_test = np.array(y_test, dtype=\"int\")"
      ],
      "metadata": {
        "id": "8tSFAXpvtBDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "HYPER-PARAMETERS"
      ],
      "metadata": {
        "id": "vq-1QzxgSOR9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "epochs = 85\n",
        "num_classes = 20\n",
        "\n",
        "# Data Preprocessing\n",
        "subtract_pixel_mean = True\n",
        "n = 3\n",
        "\n",
        "# Select ResNet Version\n",
        "version = 2\n",
        "\n",
        "# Computed depth of ResNet model\n",
        "if version == 1:\n",
        "    depth = n * 6 + 2\n",
        "elif version == 2:\n",
        "    depth = n * 9 + 2\n",
        "\n",
        "# Model name, depth and version\n",
        "model_type = 'ResNet % dv % d' % (depth, version)\n",
        "\n",
        "# Input image dimensions.\n",
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "# Normalize data.\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "\n",
        "# If subtract pixel mean is enabled\n",
        "if subtract_pixel_mean:\n",
        "    x_train_mean = np.mean(x_train, axis = 0)\n",
        "    x_train -= x_train_mean\n",
        "    x_test -= x_train_mean\n",
        "\n",
        "# Print Training and Test Samples\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "print('y_train shape:', y_train.shape)\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "metadata": {
        "id": "8GA3YHckxoQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting learning rate for different number of Epochs\n",
        "def lr_schedule(epoch):\n",
        "    lr = 1e-3\n",
        "    if epoch > 180:\n",
        "        lr *= 0.5e-3\n",
        "    elif epoch > 160:\n",
        "        lr *= 1e-3\n",
        "    elif epoch > 120:\n",
        "        lr *= 1e-2\n",
        "    elif epoch > 80:\n",
        "        lr *= 1e-1\n",
        "    print('Learning rate: ', lr)\n",
        "    return lr"
      ],
      "metadata": {
        "id": "C3cgxZapyDYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic ResNet Building Block\n",
        "def resnet_layer(inputs,\n",
        "                 num_filters=16,\n",
        "                 kernel_size=3,\n",
        "                 strides=1,\n",
        "                 activation='relu',\n",
        "                 batch_normalization=True,\n",
        "                 conv_first=False):\n",
        "    conv=Conv2D(num_filters,\n",
        "                  kernel_size=kernel_size,\n",
        "                  strides=strides,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=l2(1e-4))\n",
        "\n",
        "    x=inputs\n",
        "    if conv_first:\n",
        "        x = conv(x)\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "    else:\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "        x = conv(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "B0QDo-NG0f40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ResNet V2 architecture\n",
        "def resnet_v2(input_shape, depth, num_classes=20):\n",
        "    if (depth - 2) % 9 != 0:\n",
        "        raise ValueError('depth should be 9n + 2 (eg 56 or 110 in [b])')\n",
        "    # Start model definition.\n",
        "    num_filters_in = 16 #8 # 16\n",
        "    num_res_blocks = int((depth - 2) / 9)\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    # V2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\n",
        "    x = resnet_layer(inputs=inputs,\n",
        "                     num_filters=num_filters_in,\n",
        "                     conv_first=True)\n",
        "\n",
        "    # Instantiate the stack of residual units\n",
        "    for stage in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            activation = 'relu'\n",
        "            batch_normalization = True\n",
        "            strides = 1\n",
        "            if stage == 0:\n",
        "                num_filters_out = num_filters_in * 4\n",
        "                if res_block == 0:  # first layer and first stage\n",
        "                    activation = None\n",
        "                    batch_normalization = False\n",
        "            else:\n",
        "                num_filters_out = num_filters_in * 2\n",
        "                if res_block == 0:  # first layer but not first stage\n",
        "                    strides = 2    # downsample\n",
        "\n",
        "            # bottleneck residual unit\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters_in,\n",
        "                             kernel_size=1,\n",
        "                             strides=strides,\n",
        "                             activation=activation,\n",
        "                             batch_normalization=batch_normalization,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_in,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_out,\n",
        "                             kernel_size=1,\n",
        "                             conv_first=False)\n",
        "            if res_block == 0:\n",
        "                # linear projection residual shortcut connection to match changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters_out,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = keras.layers.add([x, y])\n",
        "\n",
        "        num_filters_in = num_filters_out\n",
        "\n",
        "    # Add classifier on top.\n",
        "    # v2 has BN-ReLU before Pooling\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "    # outputs = idx_max(outputs)\n",
        "    print(\"outputs are \", outputs)\n",
        "\n",
        "    # Instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ],
      "metadata": {
        "id": "11wIgauj1KMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main function\n",
        "if version == 2:\n",
        "    model = resnet_v2(input_shape = input_shape, depth = depth)\n",
        "\n",
        "model.compile(loss ='categorical_crossentropy',\n",
        "              optimizer = Adam(learning_rate = lr_schedule(0)),\n",
        "              metrics =['accuracy', tf.keras.metrics.Recall(), tf.keras.metrics.Precision(),\n",
        "                        tf.keras.metrics.FalseNegatives(),\n",
        "                        tf.keras.metrics.TrueNegatives(),\n",
        "                        tf.keras.metrics.FalsePositives(),\n",
        "                        tf.keras.metrics.TruePositives()])\n",
        "\n",
        "model.summary()\n",
        "print(model_type)\n",
        "\n",
        "# Prepare model saving directory.\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'eye_classifier_% s_model.{epoch:03d}.h5' % model_type\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "filepath = os.path.join(save_dir, model_name)\n",
        "\n",
        "# Prepare callbacks for model saving and for learning rate adjustment.\n",
        "checkpoint = ModelCheckpoint(filepath = filepath,\n",
        "                             monitor ='val_acc',\n",
        "                             verbose = 1,\n",
        "                             save_best_only = True)\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(factor = np.sqrt(0.1),\n",
        "                               cooldown = 0,\n",
        "                               patience = 5,\n",
        "                               min_lr = 0.5e-6)\n",
        "\n",
        "callbacks = [checkpoint, lr_reducer, lr_scheduler]\n",
        "\n",
        "# Run training\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size = batch_size,\n",
        "          epochs = epochs,\n",
        "          validation_data =(x_test, y_test),\n",
        "          shuffle = True,\n",
        "          callbacks = callbacks)\n",
        "\n",
        "# Score trained model.\n",
        "scores = model.evaluate(x_test, y_test, verbose = 1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "metadata": {
        "id": "IHgQ4Fvz2uwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/resnet_model')"
      ],
      "metadata": {
        "id": "x-gYd-BYuTGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model = keras.models.load_model('/content/resnet_model')"
      ],
      "metadata": {
        "id": "ZloVXGOzvr_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess x_test the way it is preprocessed for the ResNet\n",
        "# Normalize data.\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "\n",
        "# Subtract pixel mean\n",
        "x_train_mean = np.mean(x_train, axis = 0)\n",
        "x_train -= x_train_mean\n",
        "x_test -= x_train_mean"
      ],
      "metadata": {
        "id": "zwPbnH9bYse5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtain y_pred\n",
        "y_pred = resnet_model.predict(x_test)"
      ],
      "metadata": {
        "id": "AvZ82G6BYt4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change y_pred from one-hot to int\n",
        "y_pred_toInt = []\n",
        "for i in range(np.shape(y_pred)[0]):\n",
        "  y_pred_toInt.append(np.argmax(y_pred[i]))"
      ],
      "metadata": {
        "id": "lrBDQ-NyY1f2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Quick check for accuracy\n",
        "wrong = 0\n",
        "correct = 0\n",
        "for i in range(np.shape(y_pred_toInt)[0]):\n",
        "  if y_pred_toInt[i] != y_test[i]:\n",
        "    wrong += 1\n",
        "  else:\n",
        "    correct += 1\n",
        "print(\"wrong: \", wrong)\n",
        "print(\"Correct: \", correct)"
      ],
      "metadata": {
        "id": "KPhTZz_mY3DK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "y_true = y_test\n",
        "y_pred = y_pred_toInt\n",
        "\n",
        "categories = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
        "\n",
        "cf_matrix = confusion_matrix(y_true, y_pred, labels = categories\n",
        "\n",
        "row_sums = cf_matrix.sum(axis=1)\n",
        "df_norm_col = cf_matrix / row_sums[:, np.newaxis]\n",
        "\n",
        "ax = sns.heatmap(df_norm_col, cmap='viridis', annot=False)\n",
        "ax.xaxis.tick_top()"
      ],
      "metadata": {
        "id": "kebbmrovQ4Gn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change y_test and y_pred to one-hot\n",
        "y_onehot_test = keras.utils.to_categorical(y_test, 20)\n",
        "y_onehot_pred = keras.utils.to_categorical(y_pred, 20)"
      ],
      "metadata": {
        "id": "tGmZ98ACZd8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.metrics import roc_curve, auc, RocCurveDisplay\n",
        "from itertools import cycle\n",
        "\n",
        "# Calculate the AUC of the ROC\n",
        "n_classes = 20\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "for i in range(n_classes):\n",
        "    yot = y_onehot_test[:][i]\n",
        "    yop = y_onehot_pred[:][i]\n",
        "    fpr[i], tpr[i], _ = roc_curve(yot, yop)\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "roc_auc"
      ],
      "metadata": {
        "id": "Kpi7WsgnZknO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Quick check for accuracy\n",
        "sum(roc_auc.values()) / n_classes"
      ],
      "metadata": {
        "id": "Bf_Te3WAZlp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot ROC curve\n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "colors = cycle([\"aqua\", \"darkorange\", \"cornflowerblue\"])\n",
        "for class_id, color in zip(range(n_classes), colors):\n",
        "    RocCurveDisplay.from_predictions(\n",
        "        y_onehot_test[:, class_id],\n",
        "        y_onehot_pred[:, class_id],\n",
        "        name=f\"ROC curve for {class_id}\",\n",
        "        color=color,\n",
        "        ax=ax,\n",
        "    )\n",
        "plt.plot([0, 1], [0, 1], \"k--\", label=\"chance level (AUC = 0.5)\")"
      ],
      "metadata": {
        "id": "qkEad18YZm92"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}