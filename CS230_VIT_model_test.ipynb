{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# mount drive to access files and directories\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "metadata": {
        "id": "1LcWPWyDypQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# install necessary libraries to patchify images\n",
        "!pip install patchify\n",
        "!pip install import-ipynb"
      ],
      "metadata": {
        "id": "9ap_HLSRyuEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import all necessary libraries\n",
        "import os\n",
        "import import_ipynb\n",
        "import pickle\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "import numpy as np\n",
        "import cv2\n",
        "import sys\n",
        "from patchify import patchify\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.metrics import roc_curve, auc, RocCurveDisplay\n",
        "from itertools import cycle\n",
        "from tensorflow import keras\n",
        "from glob import glob\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau, EarlyStopping"
      ],
      "metadata": {
        "id": "pGuWTx18ycAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load ViT function from vit_cs230 python file\n",
        "from vit_cs230 import ViT"
      ],
      "metadata": {
        "id": "bLoYkst3znyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define hyperparameters\n",
        "\"\"\" Hyperparameters \"\"\"\n",
        "hp = {}\n",
        "hp[\"image_size\"] = 200\n",
        "hp[\"num_channels\"] = 3\n",
        "hp[\"patch_size\"] = 25\n",
        "hp[\"num_patches\"] = (hp[\"image_size\"]**2) // (hp[\"patch_size\"]**2)\n",
        "hp[\"flat_patches_shape\"] = (hp[\"num_patches\"], hp[\"patch_size\"]*hp[\"patch_size\"]*hp[\"num_channels\"])\n",
        "\n",
        "hp[\"batch_size\"] = 32\n",
        "hp[\"lr\"] = 1e-4\n",
        "hp[\"num_epochs\"] = 500\n",
        "hp[\"num_classes\"] = 20\n",
        "hp[\"class_names\"] = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10',\n",
        "                     '11', '12', '13', '14', '15', '16', '17', '18', '19']\n",
        "\n",
        "hp[\"num_layers\"] = 12\n",
        "hp[\"hidden_dim\"] = 768\n",
        "hp[\"mlp_dim\"] = 3072\n",
        "hp[\"num_heads\"] = 12\n",
        "hp[\"dropout_rate\"] = 0.1"
      ],
      "metadata": {
        "id": "1QNdWO5tye9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define functions to patchify images and load them and labels into dataset\n",
        "def create_dir(path):\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "\n",
        "# we chose a 60/20/20 split for this VIT model\n",
        "def load_data(path, split=0.2):\n",
        "    images = shuffle(glob(os.path.join(path, \"*\", \"*\")))\n",
        "    split_size = int(len(images) * split)\n",
        "    train_x, valid_x = train_test_split(images, test_size=split_size, random_state=42)\n",
        "    train_x, test_x = train_test_split(train_x, test_size=split_size, random_state=42)\n",
        "    return train_x, valid_x, test_x\n",
        "\n",
        "def process_image_label(path):\n",
        "    # read images\n",
        "    path = path.decode()\n",
        "    image = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "    image = cv2.resize(image, (hp[\"image_size\"], hp[\"image_size\"]))\n",
        "    image = image/255.0\n",
        "\n",
        "    # patchify\n",
        "    patch_shape = (hp[\"patch_size\"], hp[\"patch_size\"], hp[\"num_channels\"])\n",
        "    patches = patchify(image, patch_shape, hp[\"patch_size\"])\n",
        "    patches = np.reshape(patches, hp[\"flat_patches_shape\"])\n",
        "    patches = patches.astype(np.float32)\n",
        "\n",
        "    # get label from name of folder containing images\n",
        "    class_name = path.split(\"/\")[-2]\n",
        "    class_idx = hp[\"class_names\"].index(class_name)\n",
        "    class_idx = np.array(class_idx, dtype=np.int32)\n",
        "\n",
        "    return patches, class_idx\n",
        "\n",
        "def parse(path):\n",
        "    patches, labels = tf.numpy_function(process_image_label, [path], [tf.float32, tf.int32])\n",
        "    labels = tf.one_hot(labels, hp[\"num_classes\"])\n",
        "    patches.set_shape(hp[\"flat_patches_shape\"])\n",
        "    labels.set_shape(hp[\"num_classes\"])\n",
        "    return patches, labels\n",
        "\n",
        "def tf_dataset(images, batch=32): # ensure compatibility with earlier declaration\n",
        "    ds = tf.data.Dataset.from_tensor_slices((images))\n",
        "    ds = ds.map(parse).batch(batch).prefetch(8)\n",
        "    return ds"
      ],
      "metadata": {
        "id": "2hzEoXaa03Bq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aEI-nX1vXzO8"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # set the seeding\n",
        "    np.random.seed(42)\n",
        "    tf.random.set_seed(42)\n",
        "\n",
        "    # declare the paths\n",
        "    dataset_path = \"/content/mured_dataset/\"\n",
        "    model_path = os.path.join(\"files\", \"model.h5\")\n",
        "\n",
        "    # load dataset\n",
        "    train_x, valid_x, test_x = load_data(dataset_path)\n",
        "    test_ds = tf_dataset(test_x, batch=hp[\"batch_size\"])\n",
        "\n",
        "    # define model\n",
        "    model = ViT(hp)\n",
        "    model.load_weights(model_path)\n",
        "    model.compile(\n",
        "        loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
        "        optimizer=tf.keras.optimizers.Adam(hp[\"lr\"]),\n",
        "        metrics=[\"acc\"]\n",
        "    )\n",
        "\n",
        "    model.evaluate(test_ds)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# extract y_test from dataset for evaluation\n",
        "data = list(test_ds)\n",
        "\n",
        "first_batches = []\n",
        "for i in range(np.shape(data)[0] - 1):\n",
        "  first_batches.append(data[i][1])\n",
        "last_batch = data[62][1]\n",
        "last_batch = np.array(last_batch, dtype=\"float\")\n",
        "\n",
        "y_test = []\n",
        "for i in range(np.shape(first_batches)[0]): # 62\n",
        "  for j in range(np.shape(first_batches)[1]):\n",
        "    y_test.append(first_batches[i][j])\n",
        "\n",
        "y_test = np.array(y_test, dtype=\"float\")\n",
        "y_test = np.append(y_test, last_batch, axis=0)"
      ],
      "metadata": {
        "id": "VcQ7_jGYv90Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get y_pred from model\n",
        "y_pred = model.predict(test_ds)"
      ],
      "metadata": {
        "id": "hC-M-iBLqFQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert one-hot embeddings to int for y_test and y_pred\n",
        "y_test_toInt = []\n",
        "for i in range(np.shape(y_test)[0]):\n",
        "  y_test_toInt.append(np.argmax(y_test[i]))\n",
        "\n",
        "y_pred_toInt = []\n",
        "for i in range(np.shape(y_pred)[0]):\n",
        "  y_pred_toInt.append(np.argmax(y_pred[i]))"
      ],
      "metadata": {
        "id": "mh4LUw51ygUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# confusion matrix\n",
        "categories = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
        "cf_matrix = confusion_matrix(y_true, y_pred, labels = categories)\n",
        "row_sums = cf_matrix.sum(axis=1)\n",
        "df_norm_col = cf_matrix / row_sums[:, np.newaxis]\n",
        "ax = sns.heatmap(df_norm_col, cmap='viridis', annot=False)\n",
        "ax.xaxis.tick_top()"
      ],
      "metadata": {
        "id": "lT7H5jIH_DZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert y_test and y_pred to one-hot\n",
        "y_onehot_test = keras.utils.to_categorical(y_test, 20)\n",
        "y_onehot_pred = keras.utils.to_categorical(y_pred, 20)"
      ],
      "metadata": {
        "id": "c-w1tjFUr7mX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate area under the curve of ROC\n",
        "n_classes = 20\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "\n",
        "for i in range(n_classes):\n",
        "    yot = y_onehot_test[:][i]\n",
        "    yop = y_onehot_pred[:][i]\n",
        "    fpr[i], tpr[i], _ = roc_curve(yot, yop)\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "roc_auc"
      ],
      "metadata": {
        "id": "uhiOJLCAr4KH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracy from average\n",
        "sum(roc_auc.values()) / n_classes"
      ],
      "metadata": {
        "id": "e_cBUvzzsnqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ROC curve\n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "colors = cycle([\"aqua\", \"darkorange\", \"cornflowerblue\"])\n",
        "for class_id, color in zip(range(n_classes), colors):\n",
        "    RocCurveDisplay.from_predictions(\n",
        "        y_onehot_test[:, class_id],\n",
        "        y_onehot_pred[:, class_id],\n",
        "        name=f\"ROC curve for {class_id}\",\n",
        "        color=color,\n",
        "        ax=ax,\n",
        "    )\n",
        "plt.plot([0, 1], [0, 1], \"k--\", label=\"chance level (AUC = 0.5)\")"
      ],
      "metadata": {
        "id": "VlwBPJDrsoqm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}